---
<a href=README.md/#top><l style="font-size:30px">Home</l></a>&nbsp;&nbsp;| <a href=behavioral.md><l style="font-size:30px">Behavioral</l></a>&nbsp;&nbsp;| <l style="font-size:35px">Applications</l>&nbsp;&nbsp;| <a href=datasets.md><l style="font-size:30px">Datasets</l></a>&nbsp;&nbsp;
---

[Scene gaze](scene_gaze.md)&nbsp;&nbsp;| [In-vehicle gaze](in-vehicle_gaze.md)&nbsp;&nbsp;| [Distraction detection](distraction_detection.md)&nbsp;&nbsp;| [Drowsiness detection](drowsiness_detection.md)&nbsp;&nbsp;| [Action anticipation](action_anticipation.md)&nbsp;&nbsp;| Driver awareness&nbsp;&nbsp;| [Self-driving](self-driving.md)&nbsp;&nbsp;| [Papers with code](papers_with_code.md)&nbsp;&nbsp;
___
*Click on each entry below to see additional information.*
<ul><a name=2023_ITSC_Heidari></a>
<details close>
<summary>Heidari et al., Multi-Depth Cross-Calibration of Gaze Tracker and LiDAR Systems, ITSC, 2023 | <a href=https://doi.org/10.1109/ITSC57777.2023.10422290>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2023_ITSC_Heidari,
    author = "Heidari, Farzan and Dalirani, Farhad and Rahman, Taufiq and Cheema, Daniel Singh and Bauer, Michael A",
    booktitle = "2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)",
    organization = "IEEE",
    pages = "1699--1705",
    title = "Multi-Depth Cross-Calibration of Gaze Tracker and LiDAR Systems",
    year = "2023"
}
</pre>
</ul>
</ul>
<ul><a name=2023_T-ITS_Wang1></a>
<details close>
<summary>Wang1 et al., Traffic Conflict Forecasting and Avoidance System Under Automated Driving System Disengagement: A Non-Intrusive Prototype Design, Trans. ITS, 2023 | <a href=https://doi.org/10.1109/TITS.2023.3320583>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@article{2023_T-ITS_Wang1,
    author = "Wang, Song and Li, Zhixia and Hu, Jia and Xu, Jin and Jiang, Shang",
    journal = "IEEE Transactions on Intelligent Transportation Systems",
    publisher = "IEEE",
    title = "Traffic Conflict Forecasting and Avoidance System Under Automated Driving System Disengagement: A Non-Intrusive Prototype Design",
    year = "2023"
}
</pre>
</ul>
</ul>
<ul><a name=2023_ITSC_Li></a>
<details close>
<summary>Li et al., Human-like Evaluation of Visual Perception System for Autonomous Vehicles based on Human Visual Attention, ITSC, 2023 | <a href=https://doi.org/10.1109/ITSC57777.2023.10422311>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2023_ITSC_Li,
    author = "Li, Chenhao and Wang, Yijin and Li, Kuang and Fan, Qianhui and Shen, Yu and Ji, Yuxiong",
    booktitle = "2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)",
    organization = "IEEE",
    pages = "5555--5560",
    title = "Human-Like Evaluation of Visual Perception System for Autonomous Vehicles Based on Human Visual Attention",
    year = "2023"
}
</pre>
</ul>
</ul>
<ul><a name=2023_IV_Dahl></a>
<details close>
<summary>Dahl et al., Intention-Aware Lane Keeping Assist Using Driver Gaze Information, IV, 2023 | <a href=https://doi.org/10.1109/IV55152.2023.10186601>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2023_IV_Dahl,
    author = "Dahl, John and de Campos, Gabriel Rodrigues and Fredriksson, Jonas",
    booktitle = "2023 IEEE Intelligent Vehicles Symposium (IV)",
    organization = "IEEE",
    pages = "1--7",
    title = "Intention-Aware Lane Keeping Assist Using Driver Gaze Information",
    year = "2023"
}
</pre>
</ul>
</ul>
<ul><a name=2022_T-ITS_Zhou></a>
<details close>
<summary>Zhou et al., Using Eye-Tracking Data to Predict Situation Awareness in Real Time During Takeover Transitions in Conditionally Automated Driving, Trans. ITS, 2021 | <a href=https://doi.org/10.1109/TITS.2021.3069776>paper</a> | <a href=https://github.com/refengchou/Situation-awareness-prediction>code</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@article{2022_T-ITS_Zhou,
    author = "Zhou, Feng and Yang, X Jessie and de Winter, Joost CF",
    journal = "IEEE Transactions on Intelligent Transportation Systems",
    number = "3",
    pages = "2284--2295",
    publisher = "IEEE",
    title = "Using eye-tracking data to predict situation awareness in real time during takeover transitions in conditionally automated driving",
    volume = "23",
    year = "2021"
}
</pre>
</ul>
</ul>
<ul><a name=2022_IV_Wu></a>
<details close>
<summary>Wu et al., Toward an Adaptive Situational Awareness Support System for Urban Driving, IV, 2022 | <a href=https://doi.org/10.1109/IV51971.2022.9827205>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2022_IV_Wu,
    author = "Wu, Tong and Sachdeva, Enna and Akash, Kumar and Wu, Xingwei and Misu, Teruhisa and Ortiz, Jorge",
    booktitle = "2022 IEEE Intelligent Vehicles Symposium (IV)",
    organization = "IEEE",
    pages = "1073--1080",
    title = "Toward an Adaptive Situational Awareness Support System for Urban Driving",
    year = "2022"
}
</pre>
</ul>
</ul>
<ul><a name=2021_T-ITS_Ahlstrom></a>
<details close>
<summary>Ahlstrom et al., Towards a Context-Dependent Multi-Buffer Driver Distraction Detection Algorithm, Trans. ITS, 2021 | <a href=https://doi.org/10.1109/TITS.2021.3060168>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@article{2021_T-ITS_Ahlstrom,
    author = {Ahlstr{\"o}m, Christer and Georgoulas, George and Kircher, Katja},
    journal = "IEEE Transactions on Intelligent Transportation Systems",
    title = "Towards a Context-Dependent Multi-Buffer Driver Distraction Detection Algorithm",
    year = "2021"
}
</pre>
</ul>
</ul>
<ul><a name=2021_IV_Aftab></a>
<details close>
<summary>Aftab et al., Multimodal Fusion Using Deep Learning Applied to Driverâ€™s Referencing of Outside-Vehicle Objects, IV, 2021 | <a href=https://doir.org/10.1109/IV48863.2021.9575815>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2021_IV_Aftab,
    author = "Aftab, Abdul Rafey and Von Der Beeck, Michael and Rohrhirsch, Steven and Diotte, Benoit and Feld, Michael",
    booktitle = "2021 IEEE Intelligent Vehicles Symposium (IV)",
    organization = "IEEE",
    pages = "1108--1115",
    title = "Multimodal Fusion Using Deep Learning Applied to Driver's Referencing of Outside-Vehicle Objects",
    year = "2021"
}
</pre>
</ul>
</ul>
<ul><a name=2021_IROS_Zhu></a>
<details close>
<summary>Zhu et al., Improving Driver Situation Awareness Prediction using Human Visual Sensory and Memory Mechanism, IROS, 2021 | <a href=https://doi.org/10.1109/IROS51168.2021.9636112>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2021_IROS_Zhu,
    author = "Zhu, Haibei and Misu, Teruhisa and Martin, Sujitha and Wu, Xingwei and Akash, Kumar",
    booktitle = "2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
    organization = "IEEE",
    pages = "6210--6216",
    title = "Improving driver situation awareness prediction using human visual sensory and memory mechanism",
    year = "2021"
}
</pre>
</ul>
</ul>
<ul><a name=2020_IV_Kim></a>
<details close>
<summary>Kim et al., Toward Real-Time Estimation of Driver Situation Awareness: An Eye-tracking Approach based on Moving Objects of Interest, IV, 2020 | <a href=https://doi.org/10.1109/IV47402.2020.9304770>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2020_IV_Kim,
    author = "Kim, Hyungil and Martin, Sujitha and Tawari, Ashish and Misu, Teruhisa and Gabbard, Joseph L",
    booktitle = "IV",
    title = "Toward Real-Time Estimation of Driver Situation Awareness: An Eye-tracking Approach based on Moving Objects of Interest",
    year = "2020"
}
</pre>
</ul>
</ul>
<ul><a name=2020_IROS_Dua></a>
<details close>
<summary>Dua et al., DGAZE: Driver Gaze Mapping on Road, IROS, 2020 | <a href=https://doi.org/10.1109/IROS45743.2020.9341782>paper</a></summary>
<ul>
Dataset(s): <a href=datasets.md#DGAZE>DGAZE</a>
</ul>
<ul>
<pre>
@inproceedings{2020_IROS_Dua,
    author = "Dua, Isha and John, Thrupthi Ann and Gupta, Riya and Jawahar, CV",
    booktitle = "IROS",
    title = "DGAZE: Driver Gaze Mapping on Road",
    year = "2020"
}
</pre>
</ul>
</ul>
<ul><a name=2019_T-ITS_Yang></a>
<details close>
<summary>Yang et al., A Dual-Cameras-Based Driver Gaze Mapping System With an Application on Non-Driving Activities Monitoring, Trans. ITS, 2019 | <a href=https://doi.org/10.1109/TITS.2019.2939676>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@article{2019_T-ITS_Yang,
    author = "Yang, Lichao and Dong, Kuo and Dmitruk, Arkadiusz Jan and Brighton, James and Zhao, Yifan",
    journal = "IEEE Transactions on Intelligent Transportation Systems",
    number = "10",
    pages = "4318--4327",
    title = "A dual-cameras-based driver gaze mapping system with an application on non-driving activities monitoring",
    volume = "21",
    year = "2019"
}
</pre>
</ul>
</ul>
<ul><a name=2019_IV_Schwehr></a>
<details close>
<summary>Schwehr et al., How to Evaluate Object-of-Fixation Detection, IV, 2019 | <a href=https://doi.org/10.1109/IVS.2019.8814224>paper</a></summary>
<ul>
Dataset(s): <a href=datasets.md#PRORETA 4>PRORETA 4</a>
</ul>
<ul>
<pre>
@inproceedings{2019_IV_Schwehr,
    author = "Schwehr, Julian and Knaust, Moritz and Willert, Volker",
    booktitle = "IV",
    title = "How to evaluate object-of-fixation detection",
    year = "2019"
}
</pre>
</ul>
</ul>
<ul><a name=2019_IV_Gillmeier></a>
<details close>
<summary>Gillmeier et al., Prediction of ego vehicle trajectories based on driver intention and environmental context, IV, 2019 | <a href=https://doi.org/10.1109/IVS.2019.8814138>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2019_IV_Gillmeier,
    author = "Gillmeier, Katharina and Diederichs, Frederik and Spath, Dieter",
    booktitle = "IV",
    title = "Prediction of ego vehicle trajectories based on driver intention and environmental context",
    year = "2019"
}
</pre>
</ul>
</ul>
<ul><a name=2019_ACM_Ma></a>
<details close>
<summary>Ma et al., GazeFCW: Filter Collision Warning Triggers by Detecting Driverâ€™s Gaze Area, Workshop on Machine Learning on Edge in Sensor Systems, 2019 | <a href=https://doi.org/10.1145/3362743.3362962>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2019_ACM_Ma,
    author = "Ma, Yinan and Wu, Jing and Long, Chengnian",
    booktitle = "SenSys-ML",
    title = "GazeFCW: Filter Collision Warning Triggers by Detecting Driver's Gaze Area",
    year = "2019"
}
</pre>
</ul>
</ul>
<ul><a name=2018_T-ITS_Tran></a>
<details close>
<summary>Tran et al., A Human-Vehicle Collaborative Driving Framework for Driver Assistance, Trans. ITS, 2018 | <a href=https://doi.org/10.1109/TITS.2018.2878027>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@article{2018_T-ITS_Tran,
    author = "Tran, Duy and Du, Jianhao and Sheng, Weihua and Osipychev, Denis and Sun, Yuge and Bai, He",
    journal = "IEEE Transactions on Intelligent Transportation Systems",
    number = "9",
    pages = "3470--3485",
    title = "A human-vehicle collaborative driving framework for driver assistance",
    volume = "20",
    year = "2018"
}
</pre>
</ul>
</ul>
<ul><a name=2018_IV_Martin></a>
<details close>
<summary>Martin et al., Object of Fixation Estimation by Joint Analysis of Gaze and Object Dynamics, IV, 2018 | <a href=https://doi.org/10.1109/IVS.2018.8500532>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2018_IV_Martin,
    author = "Martin, Sujitha and Tawari, Ashish",
    booktitle = "IV",
    title = "Object of fixation estimation by joint analysis of gaze and object dynamics",
    year = "2018"
}
</pre>
</ul>
</ul>
<ul><a name=2018_ITSC_Schwehr></a>
<details close>
<summary>Schwehr et al., Multi-Hypothesis Multi-Model Driverâ€™s Gaze Target Tracking, ITSC, 2018 | <a href=https://doi.org/10.1109/ITSC.2018.8569655>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2018_ITSC_Schwehr,
    author = "Schwehr, Julian and Willert, Volker",
    booktitle = "ITSC",
    title = "Multi-hypothesis multi-model driver's gaze target tracking",
    year = "2018"
}
</pre>
</ul>
</ul>
<ul><a name=2017_IV_Zabihi></a>
<details close>
<summary>Zabihi et al., Detection and Recognition of Traffic Signs Inside the Attentional Visual Field of Drivers, IV, 2017 | <a href=https://doi.org/10.1109/IVS.2017.7995781>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2017_IV_Zabihi,
    author = "Zabihi, Sayed Jamal and Zabihi, SM and Beauchemin, Steven S and Bauer, Michael A",
    booktitle = "IV",
    title = "Detection and recognition of traffic signs inside the attentional visual field of drivers",
    year = "2017"
}
</pre>
</ul>
</ul>
<ul><a name=2017_ITSC_Schwehr></a>
<details close>
<summary>Schwehr et al., Driverâ€™s Gaze Prediction in Dynamic Automotive Scenes, ITSC, 2017 | <a href=https://doi.org/10.1109/ITSC.2017.8317586>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2017_ITSC_Schwehr,
    author = "Schwehr, Julian and Willert, Volker",
    booktitle = "ITSC",
    title = "Driver's gaze prediction in dynamic automotive scenes",
    year = "2017"
}
</pre>
</ul>
</ul>
<ul><a name=2016_IV_Roth></a>
<details close>
<summary>Roth et al., Driver and Pedestrian Awareness-based Collision Risk Analysis, IV, 2016 | <a href=https://doi.org/10.1109/IVS.2016.7535425>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2016_IV_Roth,
    author = "Roth, Markus and Flohr, Fabian and Gavrila, Dariu M",
    booktitle = "IV",
    title = "Driver and pedestrian awareness-based collision risk analysis",
    year = "2016"
}
</pre>
</ul>
</ul>
<ul><a name=2016_ICRA_Langner></a>
<details close>
<summary>Langner et al., Traffic Awareness Driver Assistance based on Stereovision, Eye-tracking, and Head-Up Display, ICRA, 2016 | <a href=https://doi.org/10.1109/ICRA.2016.7487485>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2016_ICRA_Langner,
    author = "Langner, Tobias and Seifert, Daniel and Fischer, Bennet and Goehring, Daniel and Ganjineh, Tinosch and Rojas, Ra{\'u}l",
    booktitle = "ICRA",
    title = "Traffic awareness driver assistance based on stereovision, eye-tracking, and head-up display",
    year = "2016"
}
</pre>
</ul>
</ul>
<ul><a name=2015_ITSC_Diederichs></a>
<details close>
<summary>Diederichs et al., Driver Intention Algorithm for Pedestrian Protection and Automated Emergency Braking Systems, ITSC, 2015 | <a href=https://doi.org/10.1109/ITSC.2015.174>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2015_ITSC_Diederichs,
    author = {Diederichs, Frederik and Sch{\"u}ttke, Tobias and Spath, Dieter},
    booktitle = "ITSC",
    title = "Driver intention algorithm for pedestrian protection and automated emergency braking systems",
    year = "2015"
}
</pre>
</ul>
</ul>
<ul><a name=2014_IV_Zabihi></a>
<details close>
<summary>Zabihi et al., Frame-Rate Vehicle Detection within the Attentional Visual Area of Drivers, IV, 2014 | <a href=https://doi.org/10.1109/IVS.2014.6856601>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2014_IV_Zabihi,
    author = "Zabihi, SM and Beauchemin, Steven S and De Medeiros, EAM and Bauer, Michael A",
    booktitle = "IV",
    title = "Frame-rate vehicle detection within the attentional visual area of drivers",
    year = "2014"
}
</pre>
</ul>
</ul>
<ul><a name=2014_IV_Kowsari></a>
<details close>
<summary>Kowsari et al., Multi-Depth Cross-Calibration of Remote Eye Gaze Trackers and Stereoscopic Scene Systems, IV, 2014 | <a href=https://doi.org/10.1109/IVS.2014.6856450>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2014_IV_Kowsari,
    author = "Kowsari, Taha and Beauchemin, Steven S and Bauer, Michael A and Laurendeau, Denis and Teasdale, Normand",
    booktitle = "IV",
    title = "Multi-depth cross-calibration of remote eye gaze trackers and stereoscopic scene systems",
    year = "2014"
}
</pre>
</ul>
</ul>
<ul><a name=2014_IV_Doman></a>
<details close>
<summary>Doman et al., Estimation of Traffic Sign Visibility Considering Local and Global Features in a Driving Environment, IV, 2014 | <a href=https://doi.org/10.1109/IVS.2014.6856474>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2014_IV_Doman,
    author = "Doman, Keisuke and Deguchi, Daisuke and Takahashi, Tomokazu and Mekada, Yoshito and Ide, Ichiro and Murase, Hiroshi and Sakai, Utsushi",
    booktitle = "IV",
    title = "Estimation of traffic sign visibility considering local and global features in a driving environment",
    year = "2014"
}
</pre>
</ul>
</ul>
<ul><a name=2014_ITSC_Tawari_1></a>
<details close>
<summary>Tawari et al., Attention Estimation By Simultaneous Analysis of Viewer and View, ITSC, 2014 | <a href=https://doi.org/10.1109/ITSC.2014.6957880>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2014_ITSC_Tawari_1,
    author = "Tawari, Ashish and M{\o}gelmose, Andreas and Martin, Sujitha and Moeslund, Thomas B and Trivedi, Mohan M",
    booktitle = "ITSC",
    title = "Attention estimation by simultaneous analysis of viewer and view",
    year = "2014"
}
</pre>
</ul>
</ul>
<ul><a name=2014_ITSC_Tanishige></a>
<details close>
<summary>Tanishige et al., Prediction of Driverâ€™s Pedestrian Detectability by Image Processing Adaptive to Visual Fields of View, ITSC, 2014 | <a href=https://doi.org/10.1109/ITSC.2014.6957881>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2014_ITSC_Tanishige,
    author = "Tanishige, Ryunosuke and Deguchi, Daisuke and Doman, Keisuke and Mekada, Yoshito and Ide, Ichiro and Murase, Hiroshi",
    booktitle = "ITSC",
    title = "Prediction of driver's pedestrian detectability by image processing adaptive to visual fields of view",
    year = "2014"
}
</pre>
</ul>
</ul>
<ul><a name=2014_CVPR_Rezaei></a>
<details close>
<summary>Rezaei et al., Look at the Driver, Look at the Road: No Distraction! No Accident!, CVPR, 2014 | <a href=https://openaccess.thecvf.com/content_cvpr_2014/papers/Rezaei_Look_at_the_2014_CVPR_paper.pdf>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2014_CVPR_Rezaei,
    author = "Rezaei, Mahdi and Klette, Reinhard",
    booktitle = "CVPR",
    title = "{Look at the driver, look at the road: No distraction! No accident!}",
    year = "2014"
}
</pre>
</ul>
</ul>
<ul><a name=2013_IV_Bar></a>
<details close>
<summary>Bar et al., Seen and Missed Traffic Objects: A Traffic Object-Specific Awareness Estimation, IV, 2013 | <a href=https://doi.org/10.1109/IVS.2013.6629443>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2013_IV_Bar,
    author = {B{\"a}r, Tobias and Linke, Denys and Nienh{\"u}ser, Dennis and Z{\"o}llner, J Marius},
    booktitle = "IV",
    title = "Seen and missed traffic objects: A traffic object-specific awareness estimation",
    year = "2013"
}
</pre>
</ul>
</ul>
<ul><a name=2012_IV_George></a>
<details close>
<summary>George et al., DAARIA: Driver Assistance by Augmented Reality for Intelligent Automobile, IV, 2012 | <a href=https://doi.org/10.1109/IVS.2012.6232220>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2012_IV_George,
    author = "George, Paul and Thouvenin, Indira and Fremont, Vincent and Cherfaoui, V{\'e}ronique",
    booktitle = "IV",
    title = "DAARIA: Driver assistance by augmented reality for intelligent automobile",
    year = "2012"
}
</pre>
</ul>
</ul>
<ul><a name=2012_IV_Engel></a>
<details close>
<summary>Engel et al., Detectability Prediction in Dynamic Scenes for Enhanced Environment Perception, IV, 2012 | <a href=https://doi.org/10.1109/IVS.2012.6232267>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2012_IV_Engel,
    author = "Engel, David and Curio, Crist{\'o}bal",
    booktitle = "IV",
    title = "Detectability prediction in dynamic scenes for enhanced environment perception",
    year = "2012"
}
</pre>
</ul>
</ul>
<ul><a name=2012_ITSC_Mori></a>
<details close>
<summary>Mori et al., Measuring Driver Awareness Based on Correlation Between Gaze Behavior and Risks of Surrounding Vehicles, ITSC, 2012 | <a href=https://doi.org/10.1109/ITSC.2012.6338802>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2012_ITSC_Mori,
    author = "Mori, Masataka and Miyajima, Chiyomi and Angkititrakul, Pongtep and Hirayama, Takatsugu and Li, Yiyang and Kitaoka, Norihide and Takeda, Kazuya",
    booktitle = "ITSC",
    title = "Measuring driver awareness based on correlation between gaze behavior and risks of surrounding vehicles",
    year = "2012"
}
</pre>
</ul>
</ul>
<ul><a name=2011_IV_Doman></a>
<details close>
<summary>Doman et al., Estimation of Traffic Sign Visibility Considering Temporal Environmental Changes for Smart Driver Assistance, IV, 2011 | <a href=https://doi.org/10.1109/IVS.2011.5940467>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2011_IV_Doman,
    author = "Doman, Keisuke and Deguchi, Daisuke and Takahashi, Tomokazu and Mekada, Yoshito and Ide, Ichiro and Murase, Hiroshi and Tamatsu, Yukimasa",
    booktitle = "IV",
    title = "Estimation of traffic sign visibility considering temporal environmental changes for smart driver assistance",
    year = "2011"
}
</pre>
</ul>
</ul>
<ul><a name=2010_IV_Doman></a>
<details close>
<summary>Doman et al., Estimation of Traffic Sign Visibility Toward Smart Driver Assistance, IV, 2010 | <a href=https://doi.org/10.1109/IVS.2010.5548137>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2010_IV_Doman,
    author = "Doman, Keisuke and Deguchi, Daisuke and Takahashi, Tomokazu and Mekada, Yoshito and Ide, Ichiro and Murase, Hiroshi and Tamatsu, Yukimasa",
    booktitle = "IV",
    title = "Estimation of traffic sign visibility toward smart driver assistance",
    year = "2010"
}
</pre>
</ul>
</ul>
<ul><a name=2010_CVPRW_Doshi></a>
<details close>
<summary>Doshi et al., Attention Estimation by Simultaneous Observation of Viewer and View, CVPRW, 2010 | <a href=https://doi.org/10.1109/CVPRW.2010.5543272>paper</a></summary>
<ul>
Dataset(s): private
</ul>
<ul>
<pre>
@inproceedings{2010_CVPRW_Doshi,
    author = "Doshi, Anup and Trivedi, Mohan M",
    booktitle = "CVPRW",
    title = "Attention estimation by simultaneous observation of viewer and view",
    year = "2010"
}
</pre>
</ul>
</ul>
